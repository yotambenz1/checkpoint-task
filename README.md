## Overview ğŸ“
This repository contains a complete solution for deploying two Python microservices (a Flask REST API and a worker) on AWS using ECS Fargate, S3, SQS, and an Application Load Balancer (ALB). Infrastructure is managed with Terraform.

---

## Prerequisites âš¡
- [Terraform](https://www.terraform.io/downloads.html) (v1.0+ recommended)
- [AWS CLI](https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html) (configured with appropriate credentials)
- [Docker](https://docs.docker.com/get-docker/) (for building images)
- Python 3.8+

---

## Directory Structure ğŸ—‚ï¸
```
.
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ flask-app/
â”‚   â”‚   â””â”€â”€ app.py
â”‚   â””â”€â”€ worker-app/
â”‚       â””â”€â”€ worker.py
â”œâ”€â”€ terraform/
â”‚   â”œâ”€â”€ environments/
â”‚   â”‚   â”œâ”€â”€ dev/
â”‚   â”‚   â”‚   â””â”€â”€ main.tf
â”‚   â”‚   â””â”€â”€ prod/
â”‚   â”‚       â””â”€â”€ main.tf
â”‚   â””â”€â”€ modules/
â”‚       â”œâ”€â”€ alb/
â”‚       â”œâ”€â”€ ecs/
â”‚       â”œâ”€â”€ s3/
â”‚       â”œâ”€â”€ sqs/
â”‚       â””â”€â”€ ...
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ pipeline.yaml
â””â”€â”€ README.md
```
---
## Infrastructure Components ğŸ› ï¸

### Networking (VPC Module) ğŸŒ
- ğŸ—ï¸ VPC with public and private subnets across two Availability Zones
- ğŸŒ‰ NAT Gateway for private subnet internet access
- ğŸ”’ Security groups for application and database access

### Compute (ECS Module) ğŸ–¥ï¸
- ğŸ³ ECS Fargate cluster
- ğŸ§© Separate ECS services and task definitions for Flask app and worker app
- ğŸ”‘ IAM roles for task execution and resource access

### Load Balancing (ALB Module) âš–ï¸
- ğŸŒ Application Load Balancer (ALB) in public subnets
- ğŸ¯ Target group forwarding to Flask app on ECS

### Storage (S3 Module) ğŸ—„ï¸
- ğŸ“¦ S3 bucket for storing processed email data

### Messaging (SQS Module) ğŸ“¬
- ğŸ“¨ FIFO SQS queue for decoupling API and worker
- ğŸ›‘ Dead-letter queue (DLQ) for failed messages

### Parameter Store (SSM Module) ğŸ”’
- ğŸ” SSM Parameter Store for securely storing API tokens

---

## Setup Instructions ğŸ§°

### 1. Clone the Repository ğŸŒ€
```sh
git clone <your-repo-url>
cd checkpoint-task
```

### 2. Configure AWS Credentials ğŸ”‘
Ensure your AWS CLI is configured:
```sh
aws configure
```

### 3. Bootstrap Step ğŸš€
Before deploying the main infrastructure, you may need to bootstrap your AWS account for Terraform state management (e.g., S3 backend, DynamoDB table for state locking).

#### Example Bootstrap
```sh
cd terraform/bootstrap
terraform init
terraform apply
```
- ğŸª£ This will create the S3 bucket and DynamoDB table for remote state and locking.
- ğŸ“ Update your `backend` configuration in environment Terraform files as needed.

### 4. Build and Push Docker Images ğŸ³
You need to build your Docker images locally and push them to your AWS ECR repositories.  
**Replace** `<account-id>`, `<region>`, and `<repo>` with your actual AWS account ID, region, and ECR repository names.

#### 1. Authenticate Docker to ECR
```sh
aws ecr get-login-password --region <region> | docker login --username AWS --password-stdin <account-id>.dkr.ecr.<region>.amazonaws.com
```

#### 2. Build Images
```sh
# Flask app
docker build -t flask-app:latest ./apps/flask-app
# Worker app
docker build -t worker-app:latest ./apps/worker-app
```

#### 3. Tag Images
```sh
docker tag flask-app:latest <account-id>.dkr.ecr.<region>.amazonaws.com/flask-app:latest
docker tag worker-app:latest <account-id>.dkr.ecr.<region>.amazonaws.com/worker-app:latest
```

#### 4. Push Images to ECR
```sh
docker push <account-id>.dkr.ecr.<region>.amazonaws.com/flask-app:latest
docker push <account-id>.dkr.ecr.<region>.amazonaws.com/worker-app:latest
```

> **Note:**
> - ğŸ·ï¸ Make sure your ECR repositories (`flask-app` and `worker-app`) exist. You can create them with:
>   ```sh
>   aws ecr create-repository --repository-name flask-app --region <region>
>   aws ecr create-repository --repository-name worker-app --region <region>
>   ```
> - ğŸš« If you get a `denied: requested access to the resource is denied` error, check your IAM permissions and repository names.

### 5. Deploy Infrastructure with Terraform ğŸŒ
```sh
cd terraform/environments/dev  # or prod
terraform init
terraform apply
```

This will provision the VPC, ALB, ECS cluster/services, S3, SQS, and SSM parameter.

---

## Environment Variables ğŸŒ±
Environment variables for each service are set via the ECS task definition in Terraform. For local development, you can use a `.env` file in each app directory.

**Flask app:**
- ğŸ“¬ `SQS_QUEUE_URL` â€“ SQS queue URL
- ğŸ”’ `TOKEN_PARAM_NAME` â€“ SSM parameter name for the token
- ğŸŒ `AWS_REGION` â€“ AWS region

**Worker app:**
- ğŸ“¬ `SQS_QUEUE_URL` â€“ SQS queue URL
- ğŸ—„ï¸ `S3_BUCKET` â€“ S3 bucket name
- ğŸŒ `AWS_REGION` â€“ AWS region
- ğŸ“ `S3_PREFIX` â€“ S3 key prefix (default: `emails/`)
- â²ï¸ `POLL_INTERVAL` â€“ Polling interval in seconds (default: `10`)

---

## Running Locally (for testing) ğŸ§ª

### Flask App
```sh
cd apps/flask-app
pip install -r requirements.txt
export SQS_QUEUE_URL=...  # Set your test SQS URL
export TOKEN_PARAM_NAME=...  # Set your test SSM parameter name
export AWS_REGION=us-west-2
python app.py
```

### Worker App
```sh
cd apps/worker-app
pip install -r requirements.txt
export SQS_QUEUE_URL=...  # Set your test SQS URL
export S3_BUCKET=...      # Set your test S3 bucket
export AWS_REGION=us-west-2
python worker.py
```

---

## Testing the Solution ğŸ§ª
- **API:** Send a POST request to the ALB endpoint `/email` with a JSON payload as described in the Flask app.
- **Worker:** The worker will automatically poll SQS and upload messages to S3.

---

## Pipeline Workflow (CI/CD) ğŸš€

This repository includes a GitHub Actions workflow for Continuous Integration and Continuous Deployment (CI/CD), located at `.github/workflows/pipeline.yaml`.

### What the Pipeline Does ğŸ› ï¸
- ğŸ³ **Builds Docker images** for both the Flask app and the worker app.
- ğŸ” **Authenticates to AWS ECR** and pushes the latest images to the appropriate ECR repositories.
- ğŸ“¥ **Downloads the current ECS task definition** and updates it with the new image tags.
- ğŸ”„ **Registers the new ECS task definition** and triggers a new deployment of the ECS service, ensuring the latest code is running in your cluster.
- âœ… **Runs on push or pull request** to main branches, automating the deployment process.

### How It Fits Into Deployment ğŸ“¦
- â© When you push changes to the repository (e.g., after merging a feature branch), the pipeline automatically builds and deploys your updated microservices to AWS ECS.
- ğŸ”„ This ensures that your infrastructure and application code are always in sync and up-to-date with the latest changes.

### Customization âš™ï¸
- ğŸ§ª You can modify the workflow file to add steps for testing, linting, or other deployment environments as needed.
- ğŸ”‘ Make sure your GitHub repository secrets are configured with the necessary AWS credentials for deployment.

---

## Cleanup ğŸ§¹
To destroy all resources:
```sh
cd terraform/environments/dev  # or prod
terraform destroy
```

---

## Troubleshooting ğŸ†˜

### Common Issues
- ğŸ”’ **State locking conflicts:** Check the DynamoDB table used for state locking. Release any stuck locks before retrying.
- ğŸ›‚ **Permission issues:** Verify your AWS credentials and IAM permissions. Ensure your user/role can create and manage all required AWS resources.
- ğŸŒ **Network issues:** Check security group rules and VPC/subnet settings. Ensure resources are in the correct subnets and have the necessary access.
- ğŸ³ **Image pull errors:** Make sure your ECS task role has access to ECR and that images are pushed to the correct repository.
- ğŸ”‘ **SSM parameter not found:** Confirm the parameter name and value are set correctly in Terraform and exist in AWS SSM Parameter Store.

---

## Notes ğŸ’¡
- For production, use secure values for tokens and secrets.
- Review and update the Terraform variables as needed for your environment.